{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Mining for Confidence Level Detection**\n",
    "\n",
    "Lydia Lonzarich and Katie Park\n",
    "CPSC 322-01, Fall 2025"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyRandomForestClassifier, MyDecisionTreeClassifier, MyNaiveBayesClassifier, MyDecisionTreeSolo\n",
    "\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation\n",
    "\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Confidence Level Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5: 2591, 4: 978, 6: 1508, 3: 259, 7: 377, 8: 175, 9: 12, 2: 33, 1: 10, 10: 2, 0: 4}\n",
      "{6: 1914, 5: 2499, 4: 487, 3: 203, 7: 368, 8: 296, 9: 62, 2: 53, 1: 49, 0: 10, 10: 8}\n",
      "{6: 1996, 7: 607, 5: 2230, 4: 654, 3: 148, 8: 172, 9: 43, 10: 8, 2: 57, 1: 27, 0: 7}\n",
      "{5: 2019, 6: 1936, 4: 727, 7: 727, 8: 265, 3: 206, 9: 15, 2: 33, 10: 6, 1: 7, 0: 8}\n",
      "{5: 4723, 10: 364, 0: 117, 4: 622, 6: 52, 9: 56, 1: 15}\n",
      "{1: 2032, 0: 991, 2: 1319, 3: 680, 4: 361, 5: 274, 6: 132, 7: 59, 8: 44, 9: 53, 10: 4}\n",
      "{'Looking Straight': 4323, 'Center': 552, 'Looking Right': 420, 'Looking Left': 654}\n",
      "{'Partially Open': 2981, 'Closed Arms': 900, 'Open Arms': 2068}\n",
      "{'Upright': 3521, 'Stiff': 2045, 'Slouched': 383}\n"
     ]
    }
   ],
   "source": [
    "confidence_raw_data = MyPyTable().load_from_file(\"confidence_features.csv\") # the unnormalized dataset.\n",
    "confidence = confidence_raw_data.new_deep_copy() # the dataset we will normalize. This is so week retain a dataset is not affected by normalization.\n",
    "\n",
    "all_attributes = [\"body_lean_x\", \"shoulder_center_x\", \"hip_center_x\", \"spine_angle\", \"head_tilt_angle\", \"shoulder_slope\", \"head_direction\", \"arm_position\", \"posture\"]\n",
    "continuous_attributes = all_attributes[:6]\n",
    "categorical_attributes = all_attributes[6:]\n",
    "\n",
    "# normalize cols that have type=float attribute values.\n",
    "confidence.normalize_columns(continuous_attributes)\n",
    "\n",
    "# find the column indices of the attributes we're using\n",
    "att_indices = []\n",
    "for att in all_attributes:\n",
    "   att_idx = confidence.column_names.index(att)\n",
    "   att_indices.append(att_idx)\n",
    "\n",
    "# # discretize values (to make continuous attribute vals --> categorical attribute vals)\n",
    "for row_index, row in enumerate(confidence.data):\n",
    "    for val_index, value in enumerate(row):\n",
    "        if val_index in att_indices and type(confidence.data[row_index][val_index]) != str:\n",
    "            confidence.data[row_index][val_index] = myutils.my_discretizer(confidence.data[row_index][val_index])\n",
    "\n",
    "for col in confidence.get_columns(all_attributes):\n",
    "    print(myutils.get_frequency(col))\n",
    "\n",
    "# confidence.compute_summary_statistics(continuous_attributes).pretty_print()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Random Forest for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5519877675840978\n"
     ]
    }
   ],
   "source": [
    "# define X and y data\n",
    "X = [[row[idx] for idx in att_indices] for row in confidence.data]\n",
    "y = confidence.get_column(\"confidence_label\")\n",
    "\n",
    "# create a random forest classifer instance using the best N, M, and F parameters found.\n",
    "myForest = MyRandomForestClassifier(N=20, M=5, F=4)\n",
    "\n",
    "# train the random forest classifier on our train data. (class does internal split into train and test set, so here we just use internal train set).\n",
    "myForest.fit(X, y)\n",
    "\n",
    "# generate confidence label predictions using our random forest classifier. (uses internal test set).\n",
    "y_preds = myForest.predict()\n",
    "\n",
    "# display accuracy of random forest classifier.\n",
    "acc = myevaluation.accuracy_score(myForest.y_test, y_preds)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define X_train and y_train datasets\n",
    "# X = [[row[idx] for idx in att_indices] for row in confidence.data]\n",
    "# y = confidence.get_column(\"confidence_label\")\n",
    "\n",
    "\n",
    "\n",
    "# # compute k fold cross validation with k=10 folds to evaluate model performance with different N, M, and F...\n",
    "# # attempt 1: N=20, M=5, F=4\n",
    "# acc, err_rate, precision, recall, f1, y_trues, y_preds = myutils.cross_val_predict(X, y, 10, lambda: MyRandomForestClassifier(N = 20, M = 5, F = 4), True)\n",
    "# print(\"Performance metrics for M=20, M=5, F=4...\")\n",
    "# print(\"accuracy: \", acc, \", error rate: \", err_rate, \", precision: \", precision, \", recall: \", recall, \", f1: \", f1)\n",
    "\n",
    "# # attempt 2: N=20, M=7, F=2\n",
    "# acc, err_rate, precision, recall, f1, y_trues, y_preds = myutils.cross_val_predict(X, y, 10, lambda: MyRandomForestClassifier(N = 20, M = 7, F = 2), True)\n",
    "# print(\"Performance metrics for M=20, M=7, F=2...\")\n",
    "# print(\"accuracy: \", acc, \", error rate: \", err_rate, \", precision: \", precision, \", recall: \", recall, \", f1: \", f1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # create a random forest classifer instance using the best N, M, and F parameters found.\n",
    "# myForest = MyRandomForestClassifier(N = 20, M = 5, F = 4)\n",
    "\n",
    "# # train the random forest classifier on our train data.\n",
    "# myForest.fit(myForest.X_train, myForest.y_train)\n",
    "\n",
    "# # generate confidence label predictions using our random forest classifier.\n",
    "# y_preds = myForest.predict()\n",
    "\n",
    "# # display accuracy of random forest classifier.\n",
    "# print(myevaluation.accuracy_score(myForest.y_test, y_preds))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Decision Tree for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-FOLD CROSS VALIDATION (k=10) RESULTS...\n",
      "(Avg) Accuracy:  0.7334087140057289\n",
      "(Avg) Error Rate:  0.26659128599427107\n",
      "(Avg) Precision:  0.7912925659509351\n",
      "(Avg) Recall:  0.7334087140057289\n",
      "(Avg) F1 score:  0.6856578735156569\n",
      "\n",
      "==========================================\n",
      "DECISION TREE CLASSIFIER RESULTS...\n",
      "Accuracy:  0.5530071355759429\n",
      "Precision:  0.37763793297131554\n",
      "Recall:  0.5530071355759429\n",
      "F1-Score:  0.4418278072120188\n"
     ]
    }
   ],
   "source": [
    "# define X and y data\n",
    "X = [[row[idx] for idx in att_indices] for row in confidence.data]\n",
    "y = confidence.get_column(\"confidence_label\")\n",
    "\n",
    "# get all unique class labels.\n",
    "labels = list(set(y)) \n",
    "\n",
    "# compute k fold cross validation with k=10 folds to evaluate model performance across different train and test subsets of data.\n",
    "acc, err_rate, precision, recall, f1, y_trues, y_preds = myutils.cross_val_predict(X, y, 10, MyDecisionTreeClassifier, True)\n",
    "print(\"K-FOLD CROSS VALIDATION (k=10) RESULTS...\")\n",
    "print(\"(Avg) Accuracy: \", acc)\n",
    "print(\"(Avg) Error Rate: \", err_rate)\n",
    "print(\"(Avg) Precision: \", precision)\n",
    "print(\"(Avg) Recall: \", recall)\n",
    "print(\"(Avg) F1 score: \", f1)\n",
    "\n",
    "# create a decision tree instance.\n",
    "myTree = MyDecisionTreeClassifier()\n",
    "\n",
    "# train the decision tree classifer (use the same train set that we generated in the random forest class for fair classifier comparison).\n",
    "myTree.fit(myForest.X_train, myForest.y_train)\n",
    "\n",
    "# generate predictions (use the same test set that we generated in the random forest class for fair classifier comparison).\n",
    "y_pred = myTree.predict(myForest.X_test)\n",
    "\n",
    "# display decision tree performance metrics.\n",
    "print(\"\")\n",
    "print(\"==========================================\")\n",
    "print(\"DECISION TREE CLASSIFIER RESULTS...\")\n",
    "acc = myevaluation.accuracy_score(myForest.y_test, y_pred)\n",
    "precision = myevaluation.multiclass_precision_score(myForest.y_test, y_pred, labels=labels)\n",
    "recall = myevaluation.multiclass_recall_score(myForest.y_test, y_pred, labels=labels)\n",
    "f1 = myevaluation.multiclass_f1_score(myForest.y_test, y_pred, labels=labels)\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1-Score: \", f1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Naive Bayes for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-FOLD CROSS VALIDATION (k=10) RESULTS...\n",
      "(Avg) Accuracy:  0.7426554098195889\n",
      "(Avg) Error Rate:  0.2573445901804111\n",
      "(Avg) Precision:  0.7389945247869342\n",
      "(Avg) Recall:  0.7426554098195889\n",
      "(Avg) F1 score:  0.7331011558614058\n",
      "\n",
      "==========================================\n",
      "NAIVE BAYES CLASSIFIER RESULTS...\n",
      "Accuracy:  0.5688073394495413\n",
      "Precision:  0.40590627281503944\n",
      "Recall:  0.5688073394495413\n",
      "F1-Score:  0.4663228934302336\n"
     ]
    }
   ],
   "source": [
    "# define X and y data\n",
    "X = [[row[idx] for idx in att_indices] for row in confidence.data]\n",
    "y = confidence.get_column(\"confidence_label\")\n",
    "\n",
    "# get all unique class labels.\n",
    "labels = list(set(y))\n",
    "\n",
    "# compute the avg acc and error rate, avg precision, avg recall, and avg F1 over each train/test split of the data.\n",
    "acc, err_rate, precision, recall, f1, y_trues, y_preds = myutils.cross_val_predict(X, y, 10, MyNaiveBayesClassifier, True)\n",
    "print(\"K-FOLD CROSS VALIDATION (k=10) RESULTS...\")\n",
    "print(\"(Avg) Accuracy: \", acc)\n",
    "print(\"(Avg) Error Rate: \", err_rate)\n",
    "print(\"(Avg) Precision: \", precision)\n",
    "print(\"(Avg) Recall: \", recall)\n",
    "print(\"(Avg) F1 score: \", f1)\n",
    "\n",
    "# create a naive bayes classifier instance.\n",
    "my_nb = MyNaiveBayesClassifier()\n",
    "\n",
    "# train our naive bayes classifier (use the same train set that we generated in the random forest class for fair classifier comparison).\n",
    "my_nb.fit(myForest.X_train, myForest.y_train)\n",
    "\n",
    "# generate confidence label predictions (use the same test set that we generated in the random forest class for fair classifier comparison).\n",
    "y_pred = my_nb.predict(myForest.X_test)\n",
    "\n",
    "\n",
    "# display naive bayes performance metrics.\n",
    "print(\"\")\n",
    "print(\"==========================================\")\n",
    "print(\"NAIVE BAYES CLASSIFIER RESULTS...\")\n",
    "acc = myevaluation.accuracy_score(myForest.y_test, y_pred)\n",
    "precision = myevaluation.multiclass_precision_score(myForest.y_test, y_pred, labels=labels)\n",
    "recall = myevaluation.multiclass_recall_score(myForest.y_test, y_pred, labels=labels)\n",
    "f1 = myevaluation.multiclass_f1_score(myForest.y_test, y_pred, labels=labels)\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1-Score: \", f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dataset Used**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Findings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current N: 20\n",
      "['Attribute', 'att2', ['Value', 'no', ['Leaf', 'False', 5, 9]], ['Value', 'yes', ['Leaf', 'True', 4, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att2', ['Value', 'no', ['Leaf', 'False', 5, 9]], ['Value', 'yes', ['Leaf', 'True', 4, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att1', ['Value', 'Java', ['Leaf', 'False', 3, 9]], ['Value', 'Python', ['Leaf', 'True', 3, 9]], ['Value', 'R', ['Attribute', 'att0', ['Value', 'Junior', ['Leaf', 'False', 1, 3]], ['Value', 'Senior', ['Leaf', 'True', 2, 3]]]]]\n",
      "current N: 20\n",
      "['Attribute', 'att2', ['Value', 'no', ['Leaf', 'False', 5, 9]], ['Value', 'yes', ['Attribute', 'att0', ['Value', 'Junior', ['Leaf', 'False', 3, 4]], ['Value', 'Senior', ['Leaf', 'True', 1, 4]]]]]\n",
      "current N: 20\n",
      "['Attribute', 'att1', ['Value', 'Java', ['Leaf', 'False', 1, 9]], ['Value', 'Python', ['Leaf', 'True', 1, 9]], ['Value', 'R', ['Attribute', 'att0', ['Value', 'Junior', ['Leaf', 'False', 1, 7]], ['Value', 'Mid', ['Leaf', 'True', 4, 7]], ['Value', 'Senior', ['Leaf', 'True', 2, 7]]]]]\n",
      "current N: 20\n",
      "['Attribute', 'att0', ['Value', 'Junior', ['Leaf', 'True', 3, 9]], ['Value', 'Mid', ['Leaf', 'False', 3, 9]], ['Value', 'Senior', ['Leaf', 'False', 3, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att3', ['Value', 'no', ['Leaf', 'False', 6, 9]], ['Value', 'yes', ['Leaf', 'True', 3, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att2', ['Value', 'no', ['Leaf', 'False', 4, 9]], ['Value', 'yes', ['Leaf', 'True', 5, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att2', ['Value', 'no', ['Leaf', 'False', 4, 9]], ['Value', 'yes', ['Leaf', 'True', 5, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att1', ['Value', 'Java', ['Leaf', 'False', 4, 9]], ['Value', 'Python', ['Leaf', 'True', 3, 9]], ['Value', 'R', ['Leaf', 'False', 2, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att2', ['Value', 'no', ['Leaf', 'False', 4, 9]], ['Value', 'yes', ['Attribute', 'att0', ['Value', 'Junior', ['Leaf', 'False', 1, 5]], ['Value', 'Senior', ['Leaf', 'True', 4, 5]]]]]\n",
      "current N: 20\n",
      "['Attribute', 'att2', ['Value', 'no', ['Leaf', 'False', 5, 9]], ['Value', 'yes', ['Leaf', 'True', 4, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att2', ['Value', 'no', ['Leaf', 'False', 5, 9]], ['Value', 'yes', ['Leaf', 'True', 4, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att2', ['Value', 'no', ['Leaf', 'False', 3, 9]], ['Value', 'yes', ['Leaf', 'True', 6, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att2', ['Value', 'no', ['Leaf', 'False', 5, 9]], ['Value', 'yes', ['Leaf', 'True', 4, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att2', ['Value', 'no', ['Leaf', 'False', 2, 9]], ['Value', 'yes', ['Attribute', 'att1', ['Value', 'Python', ['Leaf', 'True', 4, 7]], ['Value', 'R', ['Leaf', 'False', 3, 7]]]]]\n",
      "current N: 20\n",
      "['Attribute', 'att1', ['Value', 'Java', ['Leaf', 'False', 3, 9]], ['Value', 'R', ['Leaf', 'True', 6, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att2', ['Value', 'no', ['Leaf', 'False', 6, 9]], ['Value', 'yes', ['Leaf', 'True', 3, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att2', ['Value', 'no', ['Leaf', 'False', 6, 9]], ['Value', 'yes', ['Leaf', 'True', 3, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att3', ['Value', 'no', ['Leaf', 'False', 6, 9]], ['Value', 'yes', ['Attribute', 'att1', ['Value', 'Java', ['Leaf', 'False', 1, 3]], ['Value', 'Python', ['Leaf', 'True', 1, 3]], ['Value', 'R', ['Leaf', 'True', 1, 3]]]]]\n"
     ]
    }
   ],
   "source": [
    "# interview dataset\n",
    "X_train_interview = [\n",
    "        [\"Senior\", \"Java\", \"no\", \"no\"], # False\n",
    "        [\"Senior\", \"Java\", \"no\", \"yes\"], # False\n",
    "        [\"Mid\", \"Python\", \"no\", \"no\"], # True\n",
    "        [\"Junior\", \"Python\", \"no\", \"no\"], # True \n",
    "        [\"Junior\", \"R\", \"yes\", \"no\"], # True\n",
    "        [\"Junior\", \"R\", \"yes\", \"yes\"], # False \n",
    "        [\"Mid\", \"R\", \"yes\", \"yes\"], # True\n",
    "        [\"Senior\", \"Python\", \"no\", \"no\"], # False \n",
    "        [\"Senior\", \"R\", \"yes\", \"no\"], # True \n",
    "        [\"Junior\", \"Python\", \"yes\", \"no\"], # True\n",
    "        [\"Senior\", \"Python\", \"yes\", \"yes\"], # True \n",
    "        [\"Mid\", \"Python\", \"no\", \"yes\"], # True\n",
    "        [\"Mid\", \"Java\", \"yes\", \"no\"], # True\n",
    "        [\"Junior\", \"Python\", \"no\", \"yes\"] # False\n",
    "    ]\n",
    "y_train_interview = [\"False\", \"False\", \"True\", \"True\", \"True\", \"False\", \"True\", \"False\", \"True\", \"True\", \"True\", \"True\", \"True\", \"False\"]\n",
    "\n",
    "X_test_interview = [[\"Junior\", \"Java\", \"yes\", \"no\"], [\"Junior\", \"Java\", \"yes\", \"yes\"]]\n",
    "test = MyDecisionTreeClassifier()\n",
    "\n",
    "test.fit(X_train_interview, y_train_interview)\n",
    "\n",
    "print(test.predict(X_test_interview))\n",
    "print(test.tree)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "f1062708a37074d70712b695aadee582e0b0b9f95f45576b5521424137d05fec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
