{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Mining for Confidence Level Detection**\n",
    "\n",
    "Lydia Lonzarich and Katie Park\n",
    "CPSC 322-01, Fall 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyRandomForestClassifier, MyDecisionTreeClassifier, MyNaiveBayesClassifier\n",
    "\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation\n",
    "\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_raw_data = MyPyTable().load_from_file(\"confidence_features.csv\")\n",
    "confidence = confidence_raw_data.new_deep_copy() # so the original dataset is not affected by normalization\n",
    "\n",
    "attributes = [\"body_lean_x\", \"shoulder_center_x\", \"hip_center_x\", \"spine_angle\", \"head_tilt_angle\", \"shoulder_slope\", \"head_direction\", \"arm_position\", \"posture\"]\n",
    "att_indices = []\n",
    "for att in attributes: # finds the column indices of the attributes we're using\n",
    "    att_indices.append(confidence.column_names.index(att))\n",
    "\n",
    "confidence.normalize_columns([confidence.column_names[att] for att in att_indices if type(confidence.data[0][att]) != str])\n",
    "\n",
    "# uses the discretizer \n",
    "for row_index, row in enumerate(confidence.data):\n",
    "    for val_index, value in enumerate(row):\n",
    "        if val_index in att_indices and type(confidence.data[row_index][val_index]) != str:\n",
    "            confidence.data[row_index][val_index] = myutils.my_discretizer(confidence.data[row_index][val_index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTree = MyDecisionTreeClassifier()\n",
    "myTree.fit(confidence.get_columns(attributes), confidence.get_column(\"confidence_label\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m myForest \u001b[38;5;241m=\u001b[39m MyRandomForestClassifier(N \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, M \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m, F \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m myForest\u001b[38;5;241m.\u001b[39mfit(confidence\u001b[38;5;241m.\u001b[39mget_columns(attributes), confidence\u001b[38;5;241m.\u001b[39mget_column(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfidence_label\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      4\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m myForest\u001b[38;5;241m.\u001b[39mpredict()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(myevaluation\u001b[38;5;241m.\u001b[39maccuracy_score(myForest\u001b[38;5;241m.\u001b[39my_test, y_pred))\n",
      "File \u001b[0;32m~/Documents/GU/Junior Fall ('25)/CPSC 322 Data Science Algorithms/CPSC-322-final-project/mysklearn/myclassifiers.py:328\u001b[0m, in \u001b[0;36mMyRandomForestClassifier.fit\u001b[0;34m(self, X_train, y_train, test_size, random_state)\u001b[0m\n\u001b[1;32m    325\u001b[0m tree\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m    327\u001b[0m \u001b[38;5;66;03m# predict confidence rating for test instances\u001b[39;00m\n\u001b[0;32m--> 328\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# compute the accuracy of the model compared to true and predicted class labels\u001b[39;00m\n\u001b[1;32m    331\u001b[0m acc \u001b[38;5;241m=\u001b[39m myevaluation\u001b[38;5;241m.\u001b[39maccuracy_score(y_test, y_pred)\n",
      "File \u001b[0;32m~/Documents/GU/Junior Fall ('25)/CPSC 322 Data Science Algorithms/CPSC-322-final-project/mysklearn/myclassifiers.py:161\u001b[0m, in \u001b[0;36mMyDecisionTreeClassifier.predict\u001b[0;34m(self, X_test)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test \u001b[38;5;129;01min\u001b[39;00m X_test:\n\u001b[1;32m    159\u001b[0m     curr_tree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m curr_tree[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLeaf\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;66;03m# continues down tree until it reaches a leaf node\u001b[39;00m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m curr_tree[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttribute\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    164\u001b[0m             attr_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(curr_tree[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m3\u001b[39m]) \u001b[38;5;66;03m# saves attribute index to check if value in X_test is same as value in attribute\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "myForest = MyRandomForestClassifier(N = 20, M = 7, F = 5)\n",
    "myForest.fit(confidence.get_columns(attributes), confidence.get_column(\"confidence_label\"))\n",
    "\n",
    "y_pred = myForest.predict()\n",
    "\n",
    "print(myevaluation.accuracy_score(myForest.y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dataset Used**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Findings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current N: 20\n",
      "['Attribute', 'att2', ['Value', 'no', ['Leaf', 'False', 5, 9]], ['Value', 'yes', ['Leaf', 'True', 4, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att2', ['Value', 'no', ['Leaf', 'False', 5, 9]], ['Value', 'yes', ['Leaf', 'True', 4, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att1', ['Value', 'Java', ['Leaf', 'False', 3, 9]], ['Value', 'Python', ['Leaf', 'True', 3, 9]], ['Value', 'R', ['Attribute', 'att0', ['Value', 'Junior', ['Leaf', 'False', 1, 3]], ['Value', 'Senior', ['Leaf', 'True', 2, 3]]]]]\n",
      "current N: 20\n",
      "['Attribute', 'att2', ['Value', 'no', ['Leaf', 'False', 5, 9]], ['Value', 'yes', ['Attribute', 'att0', ['Value', 'Junior', ['Leaf', 'False', 3, 4]], ['Value', 'Senior', ['Leaf', 'True', 1, 4]]]]]\n",
      "current N: 20\n",
      "['Attribute', 'att1', ['Value', 'Java', ['Leaf', 'False', 1, 9]], ['Value', 'Python', ['Leaf', 'True', 1, 9]], ['Value', 'R', ['Attribute', 'att0', ['Value', 'Junior', ['Leaf', 'False', 1, 7]], ['Value', 'Mid', ['Leaf', 'True', 4, 7]], ['Value', 'Senior', ['Leaf', 'True', 2, 7]]]]]\n",
      "current N: 20\n",
      "['Attribute', 'att0', ['Value', 'Junior', ['Leaf', 'True', 3, 9]], ['Value', 'Mid', ['Leaf', 'False', 3, 9]], ['Value', 'Senior', ['Leaf', 'False', 3, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att3', ['Value', 'no', ['Leaf', 'False', 6, 9]], ['Value', 'yes', ['Leaf', 'True', 3, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att2', ['Value', 'no', ['Leaf', 'False', 4, 9]], ['Value', 'yes', ['Leaf', 'True', 5, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att2', ['Value', 'no', ['Leaf', 'False', 4, 9]], ['Value', 'yes', ['Leaf', 'True', 5, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att1', ['Value', 'Java', ['Leaf', 'False', 4, 9]], ['Value', 'Python', ['Leaf', 'True', 3, 9]], ['Value', 'R', ['Leaf', 'False', 2, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att2', ['Value', 'no', ['Leaf', 'False', 4, 9]], ['Value', 'yes', ['Attribute', 'att0', ['Value', 'Junior', ['Leaf', 'False', 1, 5]], ['Value', 'Senior', ['Leaf', 'True', 4, 5]]]]]\n",
      "current N: 20\n",
      "['Attribute', 'att2', ['Value', 'no', ['Leaf', 'False', 5, 9]], ['Value', 'yes', ['Leaf', 'True', 4, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att2', ['Value', 'no', ['Leaf', 'False', 5, 9]], ['Value', 'yes', ['Leaf', 'True', 4, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att2', ['Value', 'no', ['Leaf', 'False', 3, 9]], ['Value', 'yes', ['Leaf', 'True', 6, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att2', ['Value', 'no', ['Leaf', 'False', 5, 9]], ['Value', 'yes', ['Leaf', 'True', 4, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att2', ['Value', 'no', ['Leaf', 'False', 2, 9]], ['Value', 'yes', ['Attribute', 'att1', ['Value', 'Python', ['Leaf', 'True', 4, 7]], ['Value', 'R', ['Leaf', 'False', 3, 7]]]]]\n",
      "current N: 20\n",
      "['Attribute', 'att1', ['Value', 'Java', ['Leaf', 'False', 3, 9]], ['Value', 'R', ['Leaf', 'True', 6, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att2', ['Value', 'no', ['Leaf', 'False', 6, 9]], ['Value', 'yes', ['Leaf', 'True', 3, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att2', ['Value', 'no', ['Leaf', 'False', 6, 9]], ['Value', 'yes', ['Leaf', 'True', 3, 9]]]\n",
      "current N: 20\n",
      "['Attribute', 'att3', ['Value', 'no', ['Leaf', 'False', 6, 9]], ['Value', 'yes', ['Attribute', 'att1', ['Value', 'Java', ['Leaf', 'False', 1, 3]], ['Value', 'Python', ['Leaf', 'True', 1, 3]], ['Value', 'R', ['Leaf', 'True', 1, 3]]]]]\n"
     ]
    }
   ],
   "source": [
    "# interview dataset\n",
    "X_train_interview = [\n",
    "        [\"Senior\", \"Java\", \"no\", \"no\"], # False\n",
    "        [\"Senior\", \"Java\", \"no\", \"yes\"], # False\n",
    "        [\"Mid\", \"Python\", \"no\", \"no\"], # True\n",
    "        [\"Junior\", \"Python\", \"no\", \"no\"], # True \n",
    "        [\"Junior\", \"R\", \"yes\", \"no\"], # True\n",
    "        [\"Junior\", \"R\", \"yes\", \"yes\"], # False \n",
    "        [\"Mid\", \"R\", \"yes\", \"yes\"], # True\n",
    "        [\"Senior\", \"Python\", \"no\", \"no\"], # False \n",
    "        [\"Senior\", \"R\", \"yes\", \"no\"], # True \n",
    "        [\"Junior\", \"Python\", \"yes\", \"no\"], # True\n",
    "        [\"Senior\", \"Python\", \"yes\", \"yes\"], # True \n",
    "        [\"Mid\", \"Python\", \"no\", \"yes\"], # True\n",
    "        [\"Mid\", \"Java\", \"yes\", \"no\"], # True\n",
    "        [\"Junior\", \"Python\", \"no\", \"yes\"] # False\n",
    "    ]\n",
    "y_train_interview = [\"False\", \"False\", \"True\", \"True\", \"True\", \"False\", \"True\", \"False\", \"True\", \"True\", \"True\", \"True\", \"True\", \"False\"]\n",
    "\n",
    "test = MyRandomForestClassifier(N = 20, M = 7, F = 2)\n",
    "\n",
    "test.fit(X_train_interview, y_train_interview)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
