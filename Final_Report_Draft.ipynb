{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Mining for Confidence Level Detection**\n",
        "\n",
        "Lydia Lonzarich and Katie Park\n",
        "\n",
        "CPSC 322-01, Fall 2025"
      ],
      "metadata": {
        "id": "DW82ohQvOIdJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "xikswvuLOWVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "\n",
        "import mysklearn.myclassifiers\n",
        "importlib.reload(mysklearn.myclassifiers)\n",
        "from mysklearn.myclassifiers import MyRandomForestClassifier, MyDecisionTreeClassifier, MyNaiveBayesClassifier, MyDecisionTreeSolo\n",
        "\n",
        "import mysklearn.myutils\n",
        "importlib.reload(mysklearn.myutils)\n",
        "import mysklearn.myutils as myutils\n",
        "\n",
        "import mysklearn.myevaluation\n",
        "importlib.reload(mysklearn.myevaluation)\n",
        "import mysklearn.myevaluation as myevaluation\n",
        "\n",
        "import mysklearn.mypytable\n",
        "importlib.reload(mysklearn.mypytable)\n",
        "from mysklearn.mypytable import MyPyTable\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "TiuuZJTxOYtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction**\n",
        "\n",
        "## Dataset Description\n",
        "\n",
        "The dataset used for this project is called \"Confidence Detection Dataset,\" from Kaggle: https://www.kaggle.com/datasets/muhammadkhubaibahmad/confidence-detection-dataset\n",
        "\n",
        "</br>\n",
        "\n",
        "The dataset contains features extracted from human body landmarks and postures to classify confidence levels, which is also what is being classified for this project.\n"
      ],
      "metadata": {
        "id": "7RT_43R0Od2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Findings\n",
        "\n",
        "3 different classifiers were used on the dataset:\n",
        "1. Random Forest Classifier\n",
        "1. Decision Tree Classifier\n",
        "1. Naive Bayes Classifier\n",
        "\n",
        "After using all 3 classifiers on the dataset, the classifier that performed the best was the Naive Bayes Classifier."
      ],
      "metadata": {
        "id": "LTcLt_WHZw48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Analysis**\n",
        "\n",
        "# Dataset Information\n",
        "\n",
        "The dataset includes 19 attributes and 1 target (as defined by the dataset author), with 5,950 rows in total.\n",
        "\n",
        "The class that is predicted from the attributes is \"confidence_label,\" which can contains the class labels:\n",
        "1. confident\n",
        "2. neutral\n",
        "3. low\n",
        "\n",
        "</br>\n",
        "\n",
        "Although there are 19 attributes used to classify confidence_label, only 9 attributes were used in the different classifier approaches. The 9 attributes were chosen as they were the only attributes that could be changed based on confidence level. Certain attributes in the dataset, such as \"eye_distance,\" for example, which represents the distance between eyes, do not change if a person is confident or not, and so only attributes that were deemed to be possible predictors for confidence_label were used. These attributes include:\n",
        "1. \"body_lean_x\"\n",
        "    * A float value representing the horizontal body lean ratio\n",
        "1. \"shoulder_center_x\"\n",
        "    * A float value representing the X-coordinate of the shoulder center\n",
        "1. \"hip_center_x\"\n",
        "    * A float value representing the X-coordinate of the hip-center\n",
        "1. \"spine_angle\"\n",
        "    * A float value representing the spine inclination angle in degrees\n",
        "1. \"head_tilt_angle\"\n",
        "    * A float value representing the head tilt angle in degrees\n",
        "1. \"shoulder_slope\"\n",
        "    * A float value representing the slope of the shoulder line\n",
        "1. \"head_direction\"\n",
        "    * A categorical value representing the head orientation (can be \"Looking Straight,\" \"Center,\" \"Looking Right,\" or \"Looking Left\")\n",
        "1. \"arm_position\"\n",
        "    * A categorical value representing the arm position (can be \"Partially Open,\" \"Closed Arms,\" or \"Open Arms\")\n",
        "1. \"posture\"\n",
        "    * A categorical vaue representing the general body posture (can be \"Upright,\" \"Stiff,\" or \"Slouched).\n"
      ],
      "metadata": {
        "id": "B32RH-FyaILD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Loading\n",
        "\n",
        "Below, the dataset is extracted and saved as a MyPyTable object. A copy is then created, as all the float values will undergo normalization and discretization for algorithm compatibility for all classifiers. The copy will ensure the original dataset's values are not changed, retaining its true values.\n",
        "\n",
        "\n",
        "The copy of the dataset then undergoes normalization, ensuring all values are between [0, 1]. After being normalized, the values then undergo discretization, wherein every 0.1 (normalized) value is set to a value between [1, 10]. This ensures algorithms such as Decision Trees have a limited number of attribute values, preventing every unique float value creating a branch in the tree."
      ],
      "metadata": {
        "id": "xdlSI92jwBsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confidence_raw_data = MyPyTable().load_from_file(\"confidence_features.csv\") # dataset before processing\n",
        "confidence = confidence_raw_data.new_deep_copy() # the dataset we will normalize. Original dataset retains its true values\n",
        "\n",
        "all_attributes = [\"body_lean_x\", \"shoulder_center_x\", \"hip_center_x\", \"spine_angle\", \"head_tilt_angle\", \"shoulder_slope\", \"head_direction\", \"arm_position\", \"posture\"]\n",
        "continuous_attributes = all_attributes[:6]\n",
        "categorical_attributes = all_attributes[6:]"
      ],
      "metadata": {
        "id": "NzIzGrRswBX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Relevant Summary Statistics\n",
        "\n",
        "\n",
        "In Figure 1 below, the distribution of class labels in the dataset are visualized, with over half being classified as \"Confident,\" and the class with the smallest percentage being \"Low,\" making up only 19.4%."
      ],
      "metadata": {
        "id": "cshMcHqrcZLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pie chart of the percentages of each confidence label in the dataset\n",
        "\n",
        "# reset figure\n",
        "plt.figure(figsize = (4, 4))\n",
        "\n",
        "# get x and y values (frequency of each confidence label)\n",
        "freq = myutils.get_frequency(confidence_raw_data.get_column(\"confidence_label\"))\n",
        "\n",
        "xs = []\n",
        "ys = []\n",
        "\n",
        "for key in freq:\n",
        "    xs.append(key)\n",
        "    ys.append(freq[key])\n",
        "\n",
        "# create the chart (with number of decimals)\n",
        "plt.pie(ys, labels = xs, autopct = \"%1.1f%%\")\n",
        "\n",
        "# add border to current figure\n",
        "fig = plt.gcf()\n",
        "\n",
        "# add title to pie chart, and change formatting\n",
        "fig.suptitle(\"Figure 1: Confidence Label Percentages\")\n",
        "fig.patch.set_edgecolor(\"black\")\n",
        "fig.patch.set_linewidth(1)\n",
        "\n",
        "plt.show"
      ],
      "metadata": {
        "id": "USyJbo3qhxni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below, Figures 2, 3, and 4 show the life cycle of our data preprocessing, with Figure 2 showing a histogram, representing the distribution of the raw, unchanged data containing the true values from the original dataset."
      ],
      "metadata": {
        "id": "Ej60qPof2Ho3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram of the body_lean_x attribute before preprocessing\n",
        "\n",
        "# reset figure\n",
        "plt.figure()\n",
        "\n",
        "# get x values\n",
        "x = confidence_raw_data.get_column(\"body_lean_x\")\n",
        "\n",
        "plt.hist(x, bins = 20, alpha = 0.75)\n",
        "plt.grid(True)\n",
        "\n",
        "# add titles\n",
        "plt.title(\"Figure 2: body_lean_x (before preprocessing)\")\n",
        "plt.xlabel(\"Horizontal body lean ratio\")\n",
        "plt.ylabel(\"Count\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7tZP20RdvMRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data then undergoes normalization, as shown in Figure 3. Figure 3 shows a histogram, representing the distribution of the dataset after being normalized to the values between [0, 1]."
      ],
      "metadata": {
        "id": "SagQwfWp2099"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram of the body_lean_x attribute after normalization\n",
        "\n",
        "# reset figure\n",
        "plt.figure()\n",
        "\n",
        "# get x values after normalization\n",
        "x = confidence.get_column(\"body_lean_x\")\n",
        "\n",
        "plt.hist(x, bins = 20, alpha = 0.75)\n",
        "plt.grid(True)\n",
        "\n",
        "# add titles\n",
        "plt.title(\"Figure 3: Body Lean X (after normalization)\")\n",
        "plt.xlabel(\"Horizontal body lean ratio\")\n",
        "plt.ylabel(\"Count\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CVxGb19fv2-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After being normalized, the values are then discretization, where every 0.1 value is set to a value between [1, 10], meaning values between [0, 0.1] are set to 1, values between (0.1, 0.2] are set to 2, etc."
      ],
      "metadata": {
        "id": "5LFuL3Qv0L6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find the column indices of the attributes we're using\n",
        "att_indices = []\n",
        "for att in all_attributes:\n",
        "   att_idx = confidence.column_names.index(att)\n",
        "   att_indices.append(att_idx)\n",
        "\n",
        "# discretize values (to make continuous attribute vals --> categorical attribute vals)\n",
        "for row_index, row in enumerate(confidence.data):\n",
        "    for val_index, value in enumerate(row):\n",
        "        if val_index in att_indices and type(confidence.data[row_index][val_index]) != str:\n",
        "            confidence.data[row_index][val_index] = myutils.my_discretizer(confidence.data[row_index][val_index])"
      ],
      "metadata": {
        "id": "H67-t0pk0w_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The distribution of the normalized and discretized values are shown in Figure 4, representing the distribution of values for the body_lean_X attribute.\n",
        "\n",
        "This normalization and discretization is done to all float values that are attributes, ensuring consistency across all numeric values for future classification."
      ],
      "metadata": {
        "id": "cCcXoC1L03FC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram of the body_lean_x attribute after discretization\n",
        "\n",
        "# reset figure\n",
        "plt.figure()\n",
        "\n",
        "# get x values after normalization AND discretization\n",
        "x = confidence.get_column(\"body_lean_x\")\n",
        "\n",
        "plt.hist(x, bins = 20, alpha = 0.75)\n",
        "plt.grid(True)\n",
        "\n",
        "# add titles\n",
        "plt.title(\"Figure 4: Body Lean X (after discretization)\")\n",
        "plt.xlabel(\"Horizontal body lean ratio\")\n",
        "plt.ylabel(\"Count\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vCKicm4K0LcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classification Results**\n",
        "\n",
        "The 3 different classification approaches that were developed were: Decision Tree classifier, Random Forest classifier, and Naive Bayes classifier."
      ],
      "metadata": {
        "id": "iUpanKA-4HTP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing Decision Tree for Classification\n",
        "\n",
        "Below, the estimated predictive accuracy of the Decision Tree classifier is found using K-fold cross validation. Then, the Decision Tree classifier is trained and used to classify unseen instances. Various performance metrics are used to verify the performance of the classifier.\n",
        "\n",
        "\n",
        "</br>\n",
        "\n",
        "\n",
        "**K-Fold Cross Validation**\n",
        "\n",
        "K-fold cross validation is used to give a robust estimate of the predictive performance of the Decision Tree model and interpret model stability by training and evaluating the model on different folds, or subsets, of the same dataset. During cross validation, the entire dataset is partitioned into k (approximately) equal folds, or subsets. Training is completed k times, wherein each fold becomes the test set exactly once.\n",
        "\n",
        "\n",
        "</br>\n",
        "\n",
        "\n",
        "**Fitting the Decision Tree Classifier**\n",
        "\n",
        "After k sets of training and testing sets are created, a decision tree is fitted for each training set. Each decision tree is created by using the Top Down Induction of Decision Trees Algorithm. This algorithm selects an attribute to split the data based on having the lowest entropy (meaning the least uncertainty). Each partition is then repeatedly partitioned until either all class values for a partion is the same, there are no more attributes to split on, or there are no more instances to partition. In all cases, a leaf node is created.\n",
        "\n",
        "\n",
        "</br>\n",
        "\n",
        "\n",
        "**Predicting Unseen Instances**\n",
        "\n",
        "After a decision tree is created for a fold, the testing set is then used against the tree to predict each instance's class label. This is done by traversing down the tree, based on the attribute value at each node.\n",
        "\n",
        "</br>\n",
        "\n",
        "\n",
        "Below is the k-fold cross validation process."
      ],
      "metadata": {
        "id": "L7LO3zvNng-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define X and y data\n",
        "X = confidence.get_column_rows(all_attributes)\n",
        "y = confidence.get_column(\"confidence_label\")\n",
        "\n",
        "# get all unique class labels.\n",
        "labels = list(set(y))\n",
        "\n",
        "# compute k fold cross validation with k=10 folds to evaluate model performance across different train and test subsets of data.\n",
        "acc, err_rate, precision, recall, f1, y_trues, y_preds = myutils.cross_val_predict(X, y, 10, MyDecisionTreeClassifier, True)"
      ],
      "metadata": {
        "id": "6lMv7ZphoDDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree Performance Metrics for k-Fold Cross Validation**\n",
        "\n",
        "For each fold in the dataset, after the Decision Tree classifier is fitted and evaluated against the test set, the performance metrics for each fold are found. After all k folds are fitted and evaluated against the test set, the average for each performance metric are found. The performance metrics include:\n",
        "- Accuracy\n",
        "- Error rate\n",
        "- Precision\n",
        "- Recall\n",
        "- F1 Score\n",
        "\n",
        "The results of each performance metrics are output below"
      ],
      "metadata": {
        "id": "evXvUcVyoJVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"K-FOLD CROSS VALIDATION (k=10) PERFORMANCE METRICS\")\n",
        "print(f\"(Average) Accuracy Score: {round(acc, 2)}\")\n",
        "print(f\"(Average) Error Rate: {round(err_rate, 2)}\")\n",
        "print(f\"(Average) Precision Score: {round(precision, 2)}\")\n",
        "print(f\"(Average) Recall Score: {round(recall, 2)}\")\n",
        "print(f\"(Average) F1 Score: {round(f1, 2)}\")"
      ],
      "metadata": {
        "id": "_kcFVbVJoeFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fitting the Final Classifier**\n",
        "\n",
        "We chose to train our model with the same training set that was generated internally by the Random Forest class in order to ensure fair comparison of our three different algorithms on the same test instances.\n",
        "\n",
        "\n",
        "\n",
        "</br>\n",
        "\n",
        "\n",
        "**Generating Final Predictions**\n",
        "\n",
        "We chose to generate predictions using the same testing set that was generated internally by the Random Forest class in order to ensure fair comparison of our three different algorithms on the same test instances."
      ],
      "metadata": {
        "id": "-445xV7so0Cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a decision tree instance.\n",
        "myTree = MyDecisionTreeClassifier()\n",
        "\n",
        "# train the decision tree classifer (use the same train set that we generated in the random forest class for fair classifier comparison).\n",
        "myTree.fit(myForest.X_train, myForest.y_train)\n",
        "\n",
        "# generate predictions (use the same test set that we generated in the random forest class for fair classifier comparison).\n",
        "y_pred = myTree.predict(myForest.X_test)"
      ],
      "metadata": {
        "id": "RbnDRzQ3o7Fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes Performance Metrics for Final Model**\n",
        "\n",
        "After the Naive Bayes Classifier has been evaluated against the test set, performance metrics are calculated and output below.\n",
        "\n",
        "We found that our Naive Bayes Classifier resulted in 55.30% accuracy."
      ],
      "metadata": {
        "id": "JZKVmTL6o_nc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"DECISION TREE CLASSIFIER RESULTS\")\n",
        "acc = myevaluation.accuracy_score(myForest.y_test, y_pred)\n",
        "precision = myevaluation.multiclass_precision_score(myForest.y_test, y_pred, labels=labels)\n",
        "recall = myevaluation.multiclass_recall_score(myForest.y_test, y_pred, labels=labels)\n",
        "f1 = myevaluation.multiclass_f1_score(myForest.y_test, y_pred, labels=labels)\n",
        "print(f\"Accuracy Score: {round(acc, 2)}\")\n",
        "print(f\"Error Rate: {round(err_rate, 2)}\")\n",
        "print(f\"Precision Score: {round(precision, 2)}\")\n",
        "print(f\"Recall Score: {round(recall, 2)}\")\n",
        "print(f\"F1 Score: {round(f1, 2)}\")"
      ],
      "metadata": {
        "id": "9f-uuOO4pGoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing Random Forest for Classification\n",
        "\n",
        "Below, the Random Forest classifier is fitted, and then used to classify unseen instances. After, various performance metrics are used to verify the performance of the Random Forest classifier.\n",
        "\n",
        "</br>\n",
        "\n",
        "**Generating Test and Training Sets**\n",
        "\n",
        "For the Random Forest classifier, a pre-processing step occurs to the given dataset, wherein both training and testing sets are generated internally. This is done by first generating a random stratified test set, consisting of one third of the original dataset, with the test set having the same class distribution as the original dataset. After the test set is created, any remaining rows in the dataset that were not selected make up the training set which is then used to fit the classifier.\n",
        "\n",
        "</br>\n",
        "\n",
        "**Fitting the Classifier**\n",
        "\n",
        "Fitting the classifier is done by creating N \"random\" decision trees using bootstrapping over the remainder set. Bootstrapping is a technique where the training set is created by randomly selecting rows with replacement, and the test set is made up of any values not in the training set. During the Top Down Induction for Decision Trees Algorithm for generating each tree in the forest, F randomly chosen attributes are selected as candidate attributes to partition the data on at each node. Note that entropy is still used to determine the best attribute to partition on, similar to the Decision Tree classifier. After all N trees have been created, the M most accurate decision trees of the N trees are selected to be used for the random forest classifier. Note: the accuracy was based on the training and testing sets found using boostrapping.\n",
        "\n",
        "For this dataset, after testing against multiple N, F, and M values, it was determined the values did not change the performance of the Forest by much, so the Random Forest for the confidence level dataset is set to:\n",
        "1. N = 20\n",
        "1. M = 5\n",
        "1. F = 4"
      ],
      "metadata": {
        "id": "QdRhdvsW4cyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define X and y data\n",
        "X = confidence.get_column_rows(all_attributes)\n",
        "y = confidence.get_column(\"confidence_label\")\n",
        "\n",
        "# create a random forest classifer instance using the best N, M, and F parameters found.\n",
        "myForest = MyRandomForestClassifier(N=20, M=5, F=4)\n",
        "\n",
        "# train the random forest classifier on our train data. (class does internal split into train and test set, so here we just use internal train set).\n",
        "myForest.fit(X, y)"
      ],
      "metadata": {
        "id": "3dFcGXoj87gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predicting Unseen Instances**\n",
        "\n",
        "After the Random Forest classifier is fitted, the testing sets found earlier are then used to against the classifier. This is done by running each unseen instance against all M trees in the forest. The class label predicted the most out of the M trees is then considered the predicted class for that unseen attribute."
      ],
      "metadata": {
        "id": "1mP4sX7f88SM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = myForest.predict()"
      ],
      "metadata": {
        "id": "pMON0P8n-5zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest Performance**\n",
        "\n",
        "After the class predictions are found against the unseen instances, various performance metrics are used against the classifier to verify its performance.\n",
        "\n",
        "\n",
        "The results of each performance metric is ouputted below."
      ],
      "metadata": {
        "id": "kC9eFlNK93-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"----- PERFORMANCE METRICS FOR RANDOM FOREST -----\")\n",
        "print(f\"Accuracy Score: {round(myevaluation.accuracy_score(myForest.y_test, y_preds), 2)}\")\n",
        "print(f\"Error Rate: {round(1 - myevaluation.accuracy_score(myForest.y_test, y_preds), 2)}\")\n",
        "print(f\"Precision Score: {round(myevaluation.multiclass_precision_score(myForest.y_test, y_preds, [\"Confident\", \"Neutral\", \"Low\"]), 2)}\")\n",
        "print(f\"Recall Score: {round(myevaluation.multiclass_recall_score(myForest.y_test, y_preds, [\"Confident\", \"Neutral\", \"Low\"]), 2)}\")\n",
        "print(f\"F1 Score: {round(myevaluation.multiclass_f1_score(myForest.y_test, y_preds, [\"Confident\", \"Neutral\", \"Low\"]), 2)}\")"
      ],
      "metadata": {
        "id": "2JeMxAcK_led"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing Naive Bayes for Classification\n",
        "\n",
        "Below, the estimated predictive accuracy of the Naive Bayes classifier is found using K-fold cross validation. Then, the Naive Bayes classifier is trained and used to classify unseen instances. Various performance metrics are used to verify the performance of the classifier.\n",
        "\n",
        "\n",
        "</br>\n",
        "\n",
        "\n",
        "**K-Fold Cross Validation**\n",
        "\n",
        "K-fold cross validation is used to give a robust estimate of the predictive performance of the Naive Bayes model and interpret model stability by training and evaluating the model on different folds, or subsets, of the same dataset. During cross validation, the entire dataset is partitioned into k (approximately) equal folds, or subsets. Training is completed k times, wherein each fold becomes the test set exactly once.\n",
        "\n",
        "\n",
        "</br>\n",
        "\n",
        "\n",
        "**Fitting the Naive Bayes Classifier**\n",
        "\n",
        "Fitting in Naive Bayes involves using the training data to estimate all probabilities the model needs to generate predictions.\n",
        "\n",
        "For each fold during training, the class priors and class conditional probabilities are computed.\n",
        "\n",
        "- Class priors are the probability of each class label ocurring in the training data. These are computed by dividing the total number of instances of each label by the total number of training instances.\n",
        "- Class conditional probabilities are the probability of each feature occurring given a specific class label. For each given class, the conditional probabilities are found by dividing the total number of instances with each feature by the total number of instances with that class.\n",
        "\n",
        "Together, the class priors and conditional probabilities serve as the \"learned\" parameters of the Naive Bayes classifier.\n",
        "\n",
        "\n",
        "</br>\n",
        "\n",
        "\n",
        "**Predicting Unseen Instances**\n",
        "\n",
        "After a Naive Bayes classifier is fitted, the testing set is then used to predict each instance's class label. This is done by computing its posterior probability for each unique class label in the dataset, which is the probability of that label occuring given the attribute values in that test instance. The posterior probability for each class is calculated by multiplying the class prior by a sum of each conditional probability for the class. Once the posterior probabilities are found for each class given the test instance, the class assigned to the test instance is the largest posterior probability found.\n",
        "\n",
        "\n",
        "</br>\n",
        "\n",
        "\n",
        "Below is the k-fold cross validation process."
      ],
      "metadata": {
        "id": "plEqSHzpfhvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define X and y data\n",
        "X = [[row[idx] for idx in att_indices] for row in confidence.data]\n",
        "y = confidence.get_column(\"conafidence_label\")\n",
        "\n",
        "# get all unique class labels.\n",
        "labels = list(set(y))\n",
        "\n",
        "# compute the avg acc and error rate, avg precision, avg recall, and avg F1 over each train/test split of the data.\n",
        "acc, err_rate, precision, recall, f1, y_trues, y_preds = myutils.cross_val_predict(X, y, 10, MyNaiveBayesClassifier, True)"
      ],
      "metadata": {
        "id": "f_CVOWs8hkgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes Performance Metrics for k-Fold Cross Validation**\n",
        "\n",
        "For each fold in the dataset, after the Naive Bayes Classifier is fitted and evaluated against the test est, the performance metrics for each fold are found. After all k folds are fitted and evaluated against the test set, the average for each performance metric is found and output below.\n",
        "\n",
        "The performance metrics include:\n",
        "1. Accuracy\n",
        "1. Error rate\n",
        "1. Precision\n",
        "1. Recall\n",
        "1. F1 Score\n",
        "\n",
        "The results of each performance metric is output below"
      ],
      "metadata": {
        "id": "0-taTRy_hz9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"K-FOLD CROSS VALIDATION (k=10) PERFORMANCE METRICS\")\n",
        "print(f\"(Average) Accuracy Score: {round(acc, 2)}\")\n",
        "print(f\"(Average) Error Rate: {round(err_rate, 2)}\")\n",
        "print(f\"(Average) Precision Score: {round(precision, 2)}\")\n",
        "print(f\"(Average) Recall Score: {round(recall, 2)}\")\n",
        "print(f\"(Average) F1 Score: {round(f1, 2)}\")"
      ],
      "metadata": {
        "id": "Ie4ZYuBWiOGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fitting the Final Classifier**\n",
        "\n",
        "We chose to train our model with the same training set that was generated internally by the Random Forest class in order to ensure fair comparison of our three different algorithms on the same test instances.\n",
        "\n",
        "\n",
        "\n",
        "</br>\n",
        "\n",
        "\n",
        "**Generating Final Predictions**\n",
        "\n",
        "We chose to generate predictions using the same testing set that was generated internally by the Random Forest class in order to ensure fair comparison of our three different algorithms on the same test instances."
      ],
      "metadata": {
        "id": "KLMqQ9y8hzuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a naive bayes classifier instance.\n",
        "my_nb = MyNaiveBayesClassifier()\n",
        "\n",
        "# train our naive bayes classifier (use the same train set that we generated in the random forest class for fair classifier comparison).\n",
        "my_nb.fit(myForest.X_train, myForest.y_train)\n",
        "\n",
        "# generate confidence label predictions (use the same test set that we generated in the random forest class for fair classifier comparison).\n",
        "y_pred = my_nb.predict(myForest.X_test)"
      ],
      "metadata": {
        "id": "ixyN2gg5jd-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes Performance Metrics for Final Model**\n",
        "\n",
        "After the Naive Bayes Classifier has been evaluated against the test set, performance metrics are calculated and output below.\n",
        "\n",
        "We found that our Naive Bayes Classifier resulted in 56.88% accuracy."
      ],
      "metadata": {
        "id": "YWHk1LZDjgNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"NAIVE BAYES CLASSIFIER RESULTS\")\n",
        "acc = myevaluation.accuracy_score(myForest.y_test, y_pred)\n",
        "precision = myevaluation.multiclass_precision_score(myForest.y_test, y_pred, labels=labels)\n",
        "recall = myevaluation.multiclass_recall_score(myForest.y_test, y_pred, labels=labels)\n",
        "f1 = myevaluation.multiclass_f1_score(myForest.y_test, y_pred, labels=labels)\n",
        "print(\"Accuracy: \", acc)\n",
        "print(\"Precision: \", precision)\n",
        "print(\"Recall: \", recall)\n",
        "print(\"F1-Score: \", f1)"
      ],
      "metadata": {
        "id": "XvwxrDZGkGFY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}